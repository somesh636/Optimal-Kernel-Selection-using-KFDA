{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              1       85             66             29        0  26.6   \n",
      "1              8      183             64              0        0  23.3   \n",
      "2              1       89             66             23       94  28.1   \n",
      "3              0      137             40             35      168  43.1   \n",
      "4              5      116             74              0        0  25.6   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "762           10      101             76             48      180  32.9   \n",
      "763            2      122             70             27        0  36.8   \n",
      "764            5      121             72             23      112  26.2   \n",
      "765            1      126             60              0        0  30.1   \n",
      "766            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabeticPedigreeFunction  Age  Target  \n",
      "0                       0.351   31       0  \n",
      "1                       0.672   32       1  \n",
      "2                       0.167   21       0  \n",
      "3                       2.288   33       1  \n",
      "4                       0.201   30       0  \n",
      "..                        ...  ...     ...  \n",
      "762                     0.171   63       0  \n",
      "763                     0.340   27       0  \n",
      "764                     0.245   30       0  \n",
      "765                     0.349   47       1  \n",
      "766                     0.315   23       0  \n",
      "\n",
      "[767 rows x 9 columns]>\n",
      "Data PIMA: \n",
      "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              1       85             66             29        0  26.6   \n",
      "1              8      183             64              0        0  23.3   \n",
      "2              1       89             66             23       94  28.1   \n",
      "3              0      137             40             35      168  43.1   \n",
      "4              5      116             74              0        0  25.6   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "762           10      101             76             48      180  32.9   \n",
      "763            2      122             70             27        0  36.8   \n",
      "764            5      121             72             23      112  26.2   \n",
      "765            1      126             60              0        0  30.1   \n",
      "766            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabeticPedigreeFunction  Age  Target  \n",
      "0                       0.351   31       0  \n",
      "1                       0.672   32       1  \n",
      "2                       0.167   21       0  \n",
      "3                       2.288   33       1  \n",
      "4                       0.201   30       0  \n",
      "..                        ...  ...     ...  \n",
      "762                     0.171   63       0  \n",
      "763                     0.340   27       0  \n",
      "764                     0.245   30       0  \n",
      "765                     0.349   47       1  \n",
      "766                     0.315   23       0  \n",
      "\n",
      "[767 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#pd.set_option('display.max_rows',None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_pima = pd.read_csv('~/Documents/Uwaterloo_Study_Docs/ECE_602/Project_final/Dataset/PIMA/pima-indians-diabetes.csv')\n",
    "data_pima.rename(columns={'1':'Target', '6':'Pregnancies', '148':'Glucose', '72': 'BloodPressure', '35':'SkinThickness', '0': 'Insulin', '33.6': 'BMI', '0.627':'DiabeticPedigreeFunction', '50':'Age'},inplace=True)\n",
    "print(data_pima.info)\n",
    "print(\"Data PIMA: \\n\", data_pima)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabeticPedigreeFunction    0\n",
       "Age                         0\n",
       "Target                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pima.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive samples are:  267\n",
      "[[  8.    183.     64.    ...   0.672  32.      1.   ]\n",
      " [  0.    137.     40.    ...   2.288  33.      1.   ]\n",
      " [  3.     78.     50.    ...   0.248  26.      1.   ]\n",
      " ...\n",
      " [  6.    190.     92.    ...   0.278  66.      1.   ]\n",
      " [  9.    170.     74.    ...   0.403  43.      1.   ]\n",
      " [  1.    126.     60.    ...   0.349  47.      1.   ]]\n"
     ]
    }
   ],
   "source": [
    "data_pima_positive = data_pima.loc[(data_pima['Target'] > 0)]\n",
    "\n",
    "# number of positive sample from the dataset\n",
    "m_plus = len(data_pima_positive.index)\n",
    "\n",
    "print(\"Total positive samples are: \", m_plus)\n",
    "\n",
    "#,'Glucose','BloodPressure','SkinThickness','Insulin', 'BMI', 'DiabeticPedigreeFunction', 'Age']]\n",
    "data_pima_positive = data_pima_positive.values\n",
    "print(data_pima_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative samples are:  500\n",
      "[[  1.     85.     66.    ...   0.351  31.      0.   ]\n",
      " [  1.     89.     66.    ...   0.167  21.      0.   ]\n",
      " [  5.    116.     74.    ...   0.201  30.      0.   ]\n",
      " ...\n",
      " [  2.    122.     70.    ...   0.34   27.      0.   ]\n",
      " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
      " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "data_pima_negative = data_pima.loc[(data_pima['Target'] < 1)]\n",
    "\n",
    "# Total number of negative samples in the dataset \n",
    "m_minus = len(data_pima_negative.index)\n",
    "print(\"Total negative samples are: \", m_minus)\n",
    "data_pima_negative = data_pima_negative.values\n",
    "print(data_pima_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positve dataset mean: \n",
      " 45.93986974615064\n"
     ]
    }
   ],
   "source": [
    "# Mean and variance calculation \n",
    "\n",
    "data_pima_Pmean = np.mean(data_pima_positive)\n",
    "print(\"Positve dataset mean: \\n\", data_pima_Pmean)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative dataset mean: \n",
      " 36.871326\n"
     ]
    }
   ],
   "source": [
    "data_pima_Nmean = np.mean(data_pima_negative)\n",
    "print(\"Negative dataset mean: \\n\", data_pima_Nmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of the Positive Dataset: \n",
      " [[3550.41035378 1721.21825956 1041.72892844 ... 3762.57273789\n",
      "  3176.45734206 2488.89479617]\n",
      " [1721.21825956 3665.28152711 1875.08592489 ... 1684.14514878\n",
      "  1455.46429461 1120.34571383]\n",
      " [1041.72892844 1875.08592489 1046.62816711 ... 1103.51118822\n",
      "   958.25022989  733.26536967]\n",
      " ...\n",
      " [3762.57273789 1684.14514878 1103.51118822 ... 4156.22917044\n",
      "  3424.18206628 2763.98880383]\n",
      " [3176.45734206 1455.46429461  958.25022989 ... 3424.18206628\n",
      "  2974.35371211 2278.97030383]\n",
      " [2488.89479617 1120.34571383  733.26536967 ... 2763.98880383\n",
      "  2278.97030383 1845.486314  ]]\n",
      "Covariance of the Negative Dataset: \n",
      " [[ 968.43845011  678.91174494 1212.65451678 ... 1252.56258222\n",
      "   874.52474667 1042.91746   ]\n",
      " [ 678.91174494 1416.76002378  947.73133661 ...  936.50025889\n",
      "  1750.52883917  755.3055075 ]\n",
      " [1212.65451678  947.73133661 1690.42308344 ... 1643.52691556\n",
      "  1263.39899667 1313.80221   ]\n",
      " ...\n",
      " [1252.56258222  936.50025889 1643.52691556 ... 1695.81084444\n",
      "  1233.59503333 1368.1229    ]\n",
      " [ 874.52474667 1750.52883917 1263.39899667 ... 1233.59503333\n",
      "  2207.195725    966.905575  ]\n",
      " [1042.91746     755.3055075  1313.80221    ... 1368.1229\n",
      "   966.905575   1136.377525  ]]\n"
     ]
    }
   ],
   "source": [
    "# covariance calculation\n",
    "pdata = data_pima_positive.values\n",
    "data_pima_Pcov = np.cov(pdata)\n",
    "ndata = data_pima_negative.values\n",
    "data_pima_Ncov = np.cov(ndata)\n",
    "print(\"Covariance of the Positive Dataset: \\n\", data_pima_Pcov)\n",
    "print(\"Covariance of the Negative Dataset: \\n\", data_pima_Ncov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J:  [[ 6.09697964e-02 -2.29209761e-04 -2.29209761e-04 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-2.29209761e-04  6.09697964e-02 -2.29209761e-04 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-2.29209761e-04 -2.29209761e-04  6.09697964e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.46319168e-02\n",
      "  -8.94427191e-05 -8.94427191e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -8.94427191e-05\n",
      "   4.46319168e-02 -8.94427191e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -8.94427191e-05\n",
      "  -8.94427191e-05  4.46319168e-02]]\n",
      "J.shape:  (767, 767)\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg as linalg\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import pdist, squareform \n",
    "from scipy import linalg\n",
    "# from scipy import linprog\n",
    "from scipy import exp \n",
    "\n",
    "one_plus = np.ones(m_plus)\n",
    "#print(\"1_+: \\n\", one_plus)\n",
    "\n",
    "one_plus_transpose = np.transpose(one_plus)\n",
    "#print(\"1_t: \\n\", one_plus_transpose)\n",
    "\n",
    "one_minus = np.ones(m_minus)\n",
    "#print(\"1_-: \\n\", one_minus)\n",
    "\n",
    "one_minus_transpose = np.transpose(one_minus)\n",
    "\n",
    "I_plus = np.identity(m_plus)\n",
    "#print(\"I: \", I)\n",
    "\n",
    "J_plus = (1/np.sqrt(m_plus)) * (I_plus - (1/m_plus) * one_plus * one_plus_transpose)\n",
    "# print(\"J_+: \\n\", J_plus)\n",
    "\n",
    "I_minus = np.identity(m_minus)\n",
    "\n",
    "\n",
    "J_minus = (1/np.sqrt(m_minus)) * (I_minus - (1/m_minus) * one_minus * one_minus_transpose)\n",
    "\n",
    "#print(\"j-.shape: \", J_minus.shape)\n",
    "#print(\"j+.shape: \", J_plus.shape)\n",
    "\n",
    "# print(\"J_-: \\n\", J_minus)\n",
    "\n",
    "# J = np.matrix(J_plus J_minus)\n",
    "# print(\"J: \\n\", J)\n",
    "\n",
    "# a_plus = np.array([[0, ((1/m_plus)*one_plus)])\n",
    "# print(\"a_plus: \", a_plus)\n",
    "J = linalg.block_diag(J_plus, J_minus)\n",
    "print(\"J: \", J)\n",
    "print(\"J.shape: \",J.shape)\n",
    "\n",
    "a_plus_1 = (1/m_plus)* one_plus\n",
    "a_plus_1 = a_plus_1.T\n",
    "a_minus_1  = (1/m_minus)* one_minus\n",
    "# print(\"a_plus_1.shape: \",a_plus_1.shape)\n",
    "# print(\"a_plus_1: \\n\", a_plus_1)\n",
    "a_plus = np.array([a_plus_1, [0]])\n",
    "# print(\"a_plus: \\n\",a_plus)\n",
    "# print(\"a_plus.shape: \", a_plus.shape)\n",
    "\n",
    "a_minus = np.array([[0], a_minus_1])\n",
    "# print(\"a_minus: \", a_minus)\n",
    "# print(\"a_minus.shape: \", a_minus.shape)\n",
    "\n",
    "a = a_plus - a_minus\n",
    "# print(\"a: \\n\", a)\n",
    "# print(\"a.shape: \",a.shape)\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Gram Matrix or the Kernel Matrix\n",
    "# sq_dist = pdist(X, 'sqeuclidean')\n",
    "# print(\"sq_dist: \\n\", sq_dist)\n",
    "# sigma = 10**0.1\n",
    "# gamma = 1/(sigma**2)\n",
    "# mat_sqr_dist = squareform(sq_dist)\n",
    "\n",
    "# G = exp(-gamma * mat_sqr_dist)\n",
    "# print(\"G: \\n\", G) \n",
    "# print(\"G.shape: \", G.shape)\n",
    "# eigval, eighvec = linalg.eigh(G)\n",
    "\n",
    "# lambda_val = 10**(-8)\n",
    "\n",
    "# func_val = (1/lambda_val)*(a.T * G*J (lambda_val*I + J*G*J)*J*G*a - a.T*G*a)\n",
    "# print(\"func_val: \",func_val)\n",
    "print(len(J))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize with linalg interior points method \n",
    "\n",
    "def f_lambda(G, lambda, J, a):\n",
    "    func_val = (1/lambda)*(a.T * G*J (lambda*I + J*G*J)*J*G*a - a.T*G*a)\n",
    "    return func_val \n",
    "\n",
    "def equal_cons(theta):\n",
    "    one = np.ones().T\n",
    "    value = 1 - (one * theta)\n",
    "    return value \n",
    "\n",
    "def inequality_cons(theta):\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60b2e3596b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"G: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"G.shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meigval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meighvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlambda_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"G: \\n\", G) \n",
    "print(\"G.shape: \", G.shape)\n",
    "eigval, eighvec = linalg.eigh(G)\n",
    "\n",
    "lambda_val = 10**(-8)\n",
    "I = np.identity(len(J))\n",
    "print(\"I: \", I)\n",
    "print(\"I.shape: \", I.shape)\n",
    "\n",
    "\n",
    "J_G = np.matmul(J,G)\n",
    "print(\"J_G: \", J_G)\n",
    "print(\"J_G.shape: \", J_G.shape)\n",
    "\n",
    "lambda_I = lambda_val*I\n",
    "\n",
    "J_G_J = np.matmul(J_G, J)\n",
    "print(\"J_G_J: \", J_G_J)\n",
    "print(\"J_G_J.shape: \", J_G_J.shape)\n",
    "\n",
    "value_1 = (lambda_I + J_G_J)\n",
    "print(\"value_1: \",value_1)\n",
    "print(\"value_1.shape: \", value_1.shape)\n",
    "\n",
    "J_G_a = np.matmul(J_G,a)\n",
    "print(\"J_G_a: \",J_G_a)\n",
    "print(\"J_G_a.shape: \", J_G_a.shape)\n",
    "\n",
    "G_J = np.matmul(G,J)\n",
    "print(\"G_J: \",G_J)\n",
    "print(\"G_J.shape: \", G_J.shape)\n",
    "\n",
    "aT_G_J = np.matmul(a.T,G_J)\n",
    "print(\"aT_G_J: \",aT_G_J)\n",
    "print(\"aT_G_J.shape: \", aT_G_J.shape)\n",
    "\n",
    "# aT_G_J_J_G_a = np.matmul(aT_G_J , J_G_a)\n",
    "# print(\"aT_G_J_J_G_a: \",aT_G_J_J_G_a)\n",
    "# print(\"aT_G_J_J_G_a.shape: \", aT_G_J_J_G_a.shape)\n",
    "\n",
    "G_a = np.matmul(G,a)\n",
    "print(\"G_a: \",G_a)\n",
    "print(\"G_a.shape: \", G_a.shape)\n",
    "\n",
    "aT_G_a = np.matmul(a.T, G_a)\n",
    "print(\"aT_G_a: \",aT_G_a)\n",
    "print(\"aT_G_a.shape: \", aT_G_a.shape)\n",
    "\n",
    "value_1Inv = linalg.inv(value_1)\n",
    "\n",
    "aT_G_J_value1Inv = np.matmul(aT_G_J, value_1Inv)\n",
    "print(\"aT_G_J_value1Inv: \",aT_G_J_value1Inv)\n",
    "print(\"aT_G_J_value1Inv.shape: \", aT_G_J_value1Inv.shape)\n",
    "\n",
    "aT_G_J_value1Inv_J_G_a = np.matmul(aT_G_J_value1Inv, J_G_a)\n",
    "print(\"aT_G_J_value1Inv_J_G_a: \",aT_G_J_value1Inv_J_G_a)\n",
    "print(\"aT_G_J_value1Inv_J_G_a.shape: \", aT_G_J_value1Inv_J_G_a.shape)\n",
    "\n",
    "func_val = (1/lambda_val)*(aT_G_J_value1Inv_J_G_a - aT_G_a)\n",
    "print(\"func_val: \", func_val)\n",
    "print(\"func_val.shape: \",func_val.shape)\n",
    "\n",
    "theta = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "print(\"theta: \", theta)\n",
    "print(\"theta.shape: \", theta.shape)\n",
    "\n",
    "one_vect = np.ones(len(theta))\n",
    "print(\"one_vect: \", one_vect)\n",
    "print(\"One_vect.shape: \", one_vect.shape)\n",
    "\n",
    "equality_cons = np.dot(one_vect.T, theta)\n",
    "print(\"equality_cons: \", equality_cons)\n",
    "print(\"equality_cons.shape: \", equality_cons.shape)\n",
    "\n",
    "negative_one_I = np.negative(np.identity(len(theta)))\n",
    "print(\"nnegative_one_I: \", negative_one_I)\n",
    "print(\"negative_one_I.shape: \", negative_one_I.shape)\n",
    "\n",
    "zero_vect_eq = np.zeros(len(theta))\n",
    "print(\"zero_vect_eq: \", zero_vect_eq)\n",
    "\n",
    "one_vect_eq = np.ones(len(theta))\n",
    "print(\"one_vect_eq: \", one_vect_eq)\n",
    "\n",
    "\n",
    "# function for optimizing the theta parameter of the kernel function\n",
    "# result = linprog(func_val, A_ub=negative_one_I, b_ub = one_vect_eq, A_eq =equality_cons , b_eq =1 , bounds=None, method='interior-point')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the optimize\n",
    "\n",
    "\n",
    "def cost_function(G):\n",
    "    lambda_val = 10**(-8)\n",
    "    I = np.identity(len(J))\n",
    "    J_G = np.matmul(J,G)\n",
    "    lambda_I = lambda_val*I\n",
    "    J_G_J = np.matmul(J_G, J)\n",
    "    value_1 = (lambda_I + J_G_J)\n",
    "    J_G_a = np.matmul(J_G,a)\n",
    "    G_J = np.matmul(G,J)\n",
    "    aT_G_J = np.matmul(a.T,G_J)\n",
    "    G_a = np.matmul(G,a)\n",
    "    aT_G_a = np.matmul(a.T, G_a)\n",
    "    value_1Inv = linalg.inv(value_1)\n",
    "    aT_G_J_value1Inv = np.matmul(aT_G_J, value_1Inv)\n",
    "    aT_G_J_value1Inv_J_G_a = np.matmul(aT_G_J_value1Inv, J_G_a)\n",
    "    func_val = (1/lambda_val)*(aT_G_J_value1Inv_J_G_a - aT_G_a)\n",
    "    return func_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6e7b630260df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquareform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "def cost_function(theta):\n",
    "\n",
    "    data_pima = pd.read_csv('~/Documents/Uwaterloo_Study_Docs/ECE_602/Project_final/Dataset/PIMA/pima-indians-diabetes.csv')\n",
    "    data_pima.rename(columns={'1':'Target', '6':'Pregnancies', '148':'Glucose', '72':'BloodPressure', '35':'SkinThickness', '0': 'Insulin',                                                    '33.6': 'BMI', '0.627':'DiabeticPedigreeFunction','50':'Age'},inplace=True)\n",
    "    X = data_pima.loc[:,:'Age'].values\n",
    "    y = data_pima['Target'].values\n",
    "    data_pima_positive = data_pima.loc[(data_pima['Target'] > 0)]\n",
    "    data_pima_negative = data_pima.loc[(data_pima['Target'] < 1)]\n",
    "\n",
    "    print(X[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)\n",
    "\n",
    "    sq_dist = pdist(X, 'sqeuclidean')\n",
    "    sigma = [10**(0.1), 10**(-0.7), 10**(-0.4), 10**(-0.1), 10**(0.2), 10**(0.5), 10**(0.8), 10**(1.1), 10**(1.4), 10**(1.7)]\n",
    "\n",
    "    G = 0\n",
    "    for value in range(10):\n",
    "        gamma = 1/(sigma[value]**2)\n",
    "        gamma = -gamma * theta[value] \n",
    "        mat_sqr_dist = squareform(sq_dist)\n",
    "        g = np.exp(gamma * mat_sqr_dist)\n",
    "        G = np.add(G, g)\n",
    "\n",
    "    # number of positive sample from the dataset\n",
    "    m_plus = len(data_pima_positive.index)\n",
    "    data_pima_positive = data_pima_positive.values\n",
    "    m_minus = len(data_pima_negative.index)\n",
    "    one_plus = np.ones(m_plus)\n",
    "    one_minus = np.ones(m_minus)\n",
    "    I_plus = np.identity(m_plus)\n",
    "    J_plus_1value = np.dot(one_plus, one_plus.T)\n",
    "    J_plus = (1/np.sqrt(m_plus)) * (I_plus - (1/m_plus) * J_plus_1value)\n",
    "    I_minus = np.identity(m_minus)\n",
    "    J_minus_1value = np.dot(one_minus, one_minus.T)\n",
    "    J_minus = (1/np.sqrt(m_minus)) * (I_minus - (1/m_minus) * J_minus_1value)\n",
    "\n",
    "    J = linalg.block_diag(J_plus, J_minus)\n",
    "    a_plus_1 = (1/m_plus)* one_plus\n",
    "    a_minus_1  = (1/m_minus)* one_minus\n",
    "    zeros_a_plus = np.zeros(len(a_minus_1))\n",
    "    a_plus = np.block([a_plus_1, zeros_a_plus])\n",
    "    zeros_a_minus = np.zeros(len(a_plus_1))\n",
    "    a_minus = np.block([zeros_a_minus, a_minus_1])\n",
    "    a = a_plus - a_minus\n",
    "    lambda_val = 10**(-8)\n",
    "    I = np.identity(len(J))\n",
    "    J_G = np.matmul(J,G)\n",
    "    lambda_I = lambda_val*I\n",
    "    J_G_J = np.matmul(J_G, J)\n",
    "    value_1 = (lambda_I + J_G_J)\n",
    "    J_G_a = np.matmul(J_G,a)\n",
    "    G_J = np.matmul(G,J)\n",
    "    aT_G_J = np.matmul(a.T,G_J)\n",
    "    G_a = np.matmul(G,a)\n",
    "    aT_G_a = np.matmul(a.T, G_a)\n",
    "    value_1Inv = linalg.inv(value_1)\n",
    "    aT_G_J_value1Inv = np.matmul(aT_G_J, value_1Inv)\n",
    "    aT_G_J_value1Inv_J_G_a = np.matmul(aT_G_J_value1Inv, J_G_a)\n",
    "    func_val = (1/lambda_val)*(aT_G_J_value1Inv_J_G_a - aT_G_a)\n",
    "    return func_val\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    import numpy as np \n",
    "    import pandas as pd \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from scipy.spatial.distance import pdist, squareform \n",
    "    from scipy import linalg\n",
    "    from scipy.optimize import linprog\n",
    "    from scipy import optimize as optimize\n",
    "\n",
    "    theta = np.array([0.1, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.09, 0.1])\n",
    "    value = cost_function(theta)\n",
    "\n",
    "    #     result = optimize.minimize(cost_function(G,J,a), theta,                         method='Newton-CG', jac=True)\n",
    "    # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvxpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ea316e5c4793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import packages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcvxpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate a random non-trivial quadratic program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cvxpy'"
     ]
    }
   ],
   "source": [
    "# Import packages.\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random non-trivial quadratic program.\n",
    "m = 15\n",
    "n = 10\n",
    "p = 5\n",
    "np.random.seed(1)\n",
    "P = np.random.randn(n, n)\n",
    "P = P.T @ P\n",
    "q = np.random.randn(n)\n",
    "G = np.random.randn(m, n)\n",
    "h = G @ np.random.randn(n)\n",
    "A = np.random.randn(p, n)\n",
    "b = np.random.randn(p)\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "x = cp.Variable(n)\n",
    "prob = cp.Problem(cp.Minimize((1/2)*cp.quad_form(x, P) + q.T @ x),\n",
    "                 [G @ x <= h,\n",
    "                  A @ x == b])\n",
    "prob.solve()\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"A solution x is\")\n",
    "print(x.value)\n",
    "print(\"A dual solution corresponding to the inequality constraints is\")\n",
    "print(prob.constraints[0].dual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "value1 = np.array([10,10,10,10])\n",
    "value2 = np.array([10,10,10,10])\n",
    "\n",
    "for value in range(len(value1)):\n",
    "    value_3 = np.matmul(value1, value2)\n",
    "\n",
    "print(value_3)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with theta formula correction\n",
    "# optimal val: #[0.09960701, 0.00995461, 0.10019745, 0.10085828, 0.10285725, 0.10042986, 0.10027806, 0.10022878, 0.09097063, 0.10042986])\n",
    "\"\"\"\n",
    "Optimization terminated successfully.\n",
    "         Current function value: -0.000021\n",
    "         Iterations: 48\n",
    "         Function evaluations: 129\n",
    " final_simplex: (array([[0.105     , 0.01      , 0.1       , 0.1       , 0.1       ,\n",
    "        0.1       , 0.1       , 0.1       , 0.09      , 0.1       ],\n",
    "       [0.10496251, 0.00999938, 0.09998458, 0.09995756, 0.10004063,\n",
    "        0.10002339, 0.10005517, 0.0999644 , 0.09002173, 0.0999916 ],\n",
    "       [0.1049787 , 0.00999978, 0.09995009, 0.09994951, 0.10005682,\n",
    "        0.10000855, 0.09999511, 0.1000293 , 0.0900362 , 0.09998975],\n",
    "       [0.10497742, 0.00999889, 0.09999771, 0.09996272, 0.10002117,\n",
    "        0.09997544, 0.10005024, 0.10001934, 0.09001566, 0.09998801],\n",
    "       [0.10495622, 0.0100033 , 0.10000583, 0.09997486, 0.10003434,\n",
    "        0.0999905 , 0.10003055, 0.10000955, 0.09003133, 0.09993341],\n",
    "       [0.10498272, 0.01000042, 0.09998368, 0.09995523, 0.10006084,\n",
    "        0.09998383, 0.10004785, 0.10000222, 0.08997184, 0.09997882],\n",
    "       [0.10502112, 0.01000143, 0.09999541, 0.09991579, 0.1000055 ,\n",
    "        0.10000409, 0.10003421, 0.09998781, 0.09002734, 0.09997429],\n",
    "       [0.1049756 , 0.01000037, 0.10002517, 0.09995235, 0.10005372,\n",
    "        0.10000786, 0.1000118 , 0.09999478, 0.09000128, 0.09998125],\n",
    "       [0.10494063, 0.01000188, 0.10001875, 0.099925  , 0.10001875,\n",
    "        0.09998438, 0.10001875, 0.10001875, 0.09001687, 0.10001875],\n",
    "       [0.10496485, 0.00999915, 0.10000934, 0.09996011, 0.10004297,\n",
    "        0.10001112, 0.10000693, 0.09998828, 0.09000829, 0.09999652],\n",
    "       [0.10497301, 0.01000039, 0.09999182, 0.09995315, 0.10000988,\n",
    "        0.10001157, 0.10003757, 0.10004281, 0.08999126, 0.0999734 ]]), array([-2.14414424e-05, -2.03405001e-05, -1.99323197e-05, -1.95557112e-05,\n",
    "       -1.93496261e-05, -1.92020011e-05, -1.91396378e-05, -1.84858205e-05,\n",
    "       -1.83239708e-05, -1.80415578e-05, -1.61221730e-05]))\n",
    "           fun: -2.1441442371594732e-05\n",
    "       message: 'Optimization terminated successfully.'\n",
    "          nfev: 129\n",
    "           nit: 48\n",
    "        status: 0\n",
    "       success: True\n",
    "             x: array([0.105, 0.01 , 0.1  , 0.1  , 0.1  , 0.1  , 0.1  , 0.1  , 0.09 ,\n",
    "       0.1  ])\n",
    "accuracy_score:  65.36796536796537\n",
    "\"\"\"\n",
    "\n",
    "# Test_1 optimal values \n",
    "\n",
    "\"\"\" OutPut: \n",
    "    Optimization terminated successfully.\n",
    "         Current function value: -0.000074\n",
    "         Iterations: 47\n",
    "         Function evaluations: 135\n",
    "        final_simplex: (array([[0.09960701, 0.00995461, 0.10019745, 0.10085828, 0.10285725,\n",
    "        0.10042986, 0.10027806, 0.10022878, 0.09097063, 0.10042986],\n",
    "       [0.09954408, 0.00995525, 0.10021614, 0.10089144, 0.10286735,\n",
    "        0.10041603, 0.10026915, 0.10024723, 0.09096191, 0.10041603],\n",
    "       [0.09956341, 0.00995926, 0.1001935 , 0.10086643, 0.10282846,\n",
    "        0.10046207, 0.10027333, 0.1002275 , 0.09096873, 0.10040155],\n",
    "       [0.09955167, 0.0099555 , 0.10020395, 0.10085516, 0.1028541 ,\n",
    "        0.10042011, 0.10030593, 0.10024551, 0.09097502, 0.10042275],\n",
    "       [0.09955294, 0.00995729, 0.10020275, 0.10086122, 0.10285152,\n",
    "        0.10040501, 0.10029491, 0.10023837, 0.0909615 , 0.10044515],\n",
    "       [0.09958431, 0.00995719, 0.10017856, 0.10085601, 0.10286269,\n",
    "        0.10038882, 0.10028565, 0.1002207 , 0.09099731, 0.10043213],\n",
    "       [0.09955748, 0.00995869, 0.10021643, 0.10081746, 0.10287772,\n",
    "        0.10041126, 0.10028516, 0.10022562, 0.09099142, 0.10041126],\n",
    "       [0.09953266, 0.00995791, 0.10018214, 0.10089053, 0.10286929,\n",
    "        0.1004056 , 0.10029265, 0.10023631, 0.09100306, 0.1004056 ],\n",
    "       [0.09957616, 0.00995769, 0.10019364, 0.10087462, 0.10288593,\n",
    "        0.10040427, 0.10029121, 0.10024594, 0.09094152, 0.10040427],\n",
    "       [0.09954811, 0.00995711, 0.1002048 , 0.100861  , 0.10283084,\n",
    "        0.10041366, 0.10026437, 0.10025088, 0.09099422, 0.10044804],\n",
    "       [0.09955299, 0.00995806, 0.10019751, 0.10085605, 0.10288105,\n",
    "        0.10041169, 0.10027986, 0.10023767, 0.09096739, 0.100422  ]]), array([-7.38256678e-05, -2.97699365e-05, -2.38919995e-05, -2.01054451e-05,\n",
    "       -1.71737624e-05, -1.44745327e-05, -1.11390064e-05, -1.10349230e-05,\n",
    "       -5.01057529e-06, -1.69794734e-06,  6.57252031e-06]))\n",
    "           fun: -7.382566780123057e-05\n",
    "       message: 'Optimization terminated successfully.'\n",
    "          nfev: 135\n",
    "           nit: 47\n",
    "        status: 0\n",
    "       success: True\n",
    "             x: array([0.09960701, 0.00995461, 0.10019745, 0.10085828, 0.10285725,\n",
    "       0.10042986, 0.10027806, 0.10022878, 0.09097063, 0.10042986])\n",
    "        \"\"\"\n",
    "\n",
    "# sqaureform outside Test\n",
    "\n",
    "\"\"\"\n",
    "Optimization terminated successfully.\n",
    "         Current function value: -0.000023\n",
    "         Iterations: 35\n",
    "         Function evaluations: 124\n",
    " final_simplex: (array([[0.10208656, 0.00984434, 0.09608656, 0.10208656, 0.10208656,\n",
    "        0.09971056, 0.10208656, 0.10208656, 0.09089424, 0.09988656],\n",
    "       [0.10207856, 0.00984373, 0.09613807, 0.10205289, 0.10207506,\n",
    "        0.09972917, 0.10211293, 0.10207168, 0.09090554, 0.09986498],\n",
    "       [0.10208623, 0.00984376, 0.09613777, 0.10204747, 0.10208939,\n",
    "        0.09971009, 0.10211726, 0.10207102, 0.09089619, 0.09987505],\n",
    "       [0.10206566, 0.00984582, 0.09614457, 0.10205595, 0.10206434,\n",
    "        0.09971417, 0.10211381, 0.10206306, 0.09089085, 0.09988272],\n",
    "       [0.10208539, 0.00984526, 0.09614272, 0.10205713, 0.10205504,\n",
    "        0.09971358, 0.10208957, 0.10208394, 0.09089686, 0.09987928],\n",
    "       [0.10207662, 0.00984531, 0.09615844, 0.1020676 , 0.10207448,\n",
    "        0.09971244, 0.10207662, 0.10207662, 0.09088998, 0.09989667],\n",
    "       [0.10203025, 0.00984331, 0.09613165, 0.10210021, 0.10208246,\n",
    "        0.09971017, 0.10213283, 0.10207741, 0.09090257, 0.09986876],\n",
    "       [0.1020826 , 0.00984188, 0.09613937, 0.10209461, 0.102076  ,\n",
    "        0.0997206 , 0.10208989, 0.1020656 , 0.0908822 , 0.09988745],\n",
    "       [0.10208063, 0.0098452 , 0.09614722, 0.10206865, 0.1020714 ,\n",
    "        0.0997144 , 0.10209006, 0.10206944, 0.09089726, 0.0998662 ],\n",
    "       [0.1021025 , 0.00984435, 0.09614177, 0.10208921, 0.10207536,\n",
    "        0.09971202, 0.10210685, 0.10200724, 0.09090431, 0.09987486],\n",
    "       [0.10211385, 0.00984387, 0.0961186 , 0.10207895, 0.10207718,\n",
    "        0.09971153, 0.10213282, 0.10207099, 0.09088026, 0.0998618 ]]), array([-2.32975098e-05, -1.96761010e-05, -1.93457229e-05, -1.92643644e-05,\n",
    "       -1.90283553e-05, -1.90166459e-05, -1.87882696e-05, -1.87842797e-05,\n",
    "       -1.86923393e-05, -1.84277940e-05, -1.77585377e-05]))\n",
    "           fun: -2.3297509754716117e-05\n",
    "       message: 'Optimization terminated successfully.'\n",
    "          nfev: 124\n",
    "           nit: 35\n",
    "        status: 0\n",
    "       success: True\n",
    "             x: array([0.10208656, 0.00984434, 0.09608656, 0.10208656, 0.10208656,\n",
    "       0.09971056, 0.10208656, 0.10208656, 0.09089424, 0.09988656])\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2239a7e27973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Sonar dataset Analysis\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit42d4110570bf49e69152afd4264194d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
